%\clearpage

\chapter*{Introduction}

\addcontentsline{toc}{chapter}{\protect\numberline{}{Introduction}}

This  work is  devoted  to the study of  the {\it scaled gradient projection (SGP) method with nonmonotone line search} to solve general  constrained convex optimization problems as follows
\begin{equation} \label{eq:OptP}
	\min \{ f(x) :~   x\in C\},
\end{equation}
where $C$ is a closed and convex subset of $\mathbb{R}^n$ and $f:\mathbb{R}^n \to \mathbb{R}$ is a continuously differentiable function. Denotes by $f^*:= \inf_{x\in C} f(x)$ the optimal value  of \eqref{eq:OptP} and by  $\Omega^*$  its  solution set, which we will assume to be nonempty unless the contrary is explicitly stated.  Problem~\eqref{eq:OptP} is a basic issue of constrained  optimization, which appears very often in various areas, including  finance,    machine learning, control theory, and signal processing, see for example \cite{Bottou_Curtis_Nocedal2018, Boyd_Ghaoui_Ferron1994, Figueiredo2007, Higham2002, Ma_Hu_Gao2015, Sra_Nowozin_Wright2012}.  Recent problems considered in most of these areas, the datasets are large or high-dimensional  and their solutions need to be approximated quickly with a reasonably accuracy. It is well known that SGP method with nonmonotone line search is among those that are suitable for this task, as will be explained below.

The  gradient projection method   is what first comes to mind when we start from the ideas of the classic optimization methods in an attempt to deal with problem \eqref{eq:OptP}.  In fact, this  method is one of the oldest known optimization methods to solve \eqref{eq:OptP}, the study of its convergence properties goes back to the works of Goldstein \cite{Goldstein1964} and Levitin and Polyak \cite{Polyak_Levitin1966}.  After these works, several variants of it have appeared over the years, resulting in a vast literature on the subject, including  \cite{yunier_roman2010, Bertsekas1976, Bertsekas1999, Fan_Wang_Yan2019, Figueiredo2007, Gong2011,   Iusem2003, Patrascu_Necoara2018, Zhang_Wang_Yang2019}. Additional reference on this subject  can be found in the recent  review  \cite{bonettini2019recent} and  references therein. Among all the variants of the gradient projection method, the scaled  version has been especially considered due to the flexibility provided in  efficient  implementations of the method; see \cite{BirginMartinezRaydan2003,10.1093/imanum/drh020,Bonettini2016, BonettiniPrato2015, Bonettini2009}.  In addition, its simplicity and easy implementation has attracted the attention of the scientific community that works on optimization over the years.  This method usually uses only first-order derivatives, which makes it very stable from a numerical point of view and therefore quite suitable for solving large-scale optimization problems, see \cite{More1990, Nesterov_Nemirovski2013, Sra_Nowozin_Wright2012, tang_golbabaee_davies2017}. At each current iteration, SGP method  moves along the direction of the negative scaled gradient, and then projects the obtained point  onto the constraint set.  
The current iteration and such projection define a feasible descent direction and a line search in this direction is performed to define the next iteration. In this way,  the performance of the method is strongly related to each of the steps we have just  mentioned. In fact, the scale matrix and the step size towards the negative scaled gradient are freely selected in order to improve the performance  of SGP method but without increasing the cost of each iteration.  Strategies  for choosing both have  their  origins in the study of  gradient  method  for unconstrained  optimization,   papers addressing  this issues include  but not limited to \cite{BB1988, BonettiniPrato2015, DaiFletcher2006,DaiHage2006, Serafino2018, Friedlander1999, Dai2006,  DaiFletcher2005,  Polyak_Levitin1966}.   It is worth mentioning that,  for suitable choices  of the scale matrix  and the  step size,  SGP merges into the well known {\it spectral gradient method}  extensively studied in \cite{BirginMartinezRaydan2003, spgsiam}.  More details  about selecting  step sizes and scale matrices  can be found in the recent  review  \cite{bonettini2019recent} and  references therein.

In this paper, we are particularly interested in the main stages that make up the SGP method, namely, in the projection calculation and in the line search employed.   It is well known that the mostly computational burden of each iteration of the SGP method is in the calculation of the projection.  Indeed, the   projection calculation requires, at each  iteration, the solution of a quadratic problem restricted to the feasible set,  which can lead to a substantial increase in the cost per iteration if the number of unknowns is large. For this reason, it may not be justified to carry out exact projections when the iterates are far from the solution of the problem. In order to reduce the computational effort spent on projections, inexact procedures that become more and more accurate when approaching the solution, have been proposed, resulting in more efficient methods;  see  for exemple   \cite{BirginMartinezRaydan2003, Bonettini2016,Golbabaee_Davies2018, Gonccalves2020, SalzoVilla2012, VillaSalzo2013, Rasch2020}.  On the other hand, nonmonotone searches can improve the probability of finding an optimal global solution, in addition to potentially improving the speed of convergence of the method as a whole, see for example \cite{Dai2002, Panier1991, Toint1996}. The concept of nonmonotone line search,  that we will use here as a synonym for  inexact line search,  have been proposed first in \cite{Grippo1986}, and  later a new nonmonotone search was proposed in \cite{ZhangHager2004}.  After these papers  others  nonmonotone searches appeared, see for example  \cite{Ahookhosh2012, MoLiuYan2007}.  In \cite{SachsSachs2011}, an interesting general framework for nonmonotone line search was proposed, and more recently modifications of it have been presented in \cite{GrapigliaSachs2017, GrapigliaSachs2020}.

The purpose of the present  paper is to present an inexact version of the SGP method, which  is inexact in two sense. First,  using  a version of  scheme introduced in \cite{BirginMartinezRaydan2003} and also a variation of the one appeared in \cite[Example 1]{VillaSalzo2013},  the inexact projection  onto the feasible  set is computed  allowing an appropriate  relative error tolerance. Second,  using the inexact  conceptual scheme for the  line search  introduced  in  \cite{GrapigliaSachs2020, SachsSachs2011}, a step size is computed  to define the next iteration.   More specifically, initially we show that the  feasible inexact  projection of \cite{BirginMartinezRaydan2003} provides greater latitude than the projection of \cite[Example 1]{VillaSalzo2013}.  In the first  convergence result presented, we show that the SGP method using the projection proposed in \cite{BirginMartinezRaydan2003} preserves the same partial convergence result as the classic method, that is, we prove that every accumulation point  of the sequence generated by the SGP method is stationary for problem~\eqref{eq:OptP}. Then, considering the inexact projection of \cite[Example 1]{VillaSalzo2013}, and  under mild  assumptions,  we establish  full asymptotic convergence results  and  some complexity bounds. The  presented analysis of the method is done using the general  nonmonotone line search scheme  introduced in \cite{GrapigliaSachs2020}. In this way, the proposed method can be adapted to several line searches and, in particular, will allow obtaining several known versions of the SGP method as particular instances,  including  \cite{yunier_roman2010,BirginMartinezRaydan2003,Iusem2003,Xihong2018}. Except for the particular case when we assume that the SGP method employs  the nonmonotone line search introduced by \cite{Grippo1986}, all other  asymptotic convergence and complexity  results are obtained without any assumption of compactness of the sub-level sets of the objective function.  Finally, it is worth mentioning that the complexity results obtained  for the SGP method with a general nonmonotone line search  are the same as in the classic case when the usual Armijo search is employed, namely,  the complexity bound  $\mathcal{O}(1/\sqrt{k})$ is unveil for finding $\epsilon$-stationary points for problem \eqref{eq:OptP} and, under convexity on $f$, the rate to find a $\epsilon$-optimal functional value is $\mathcal{O}(1/k)$.

In Section~\ref{chap:Prel}, some notations and basic results used throughout the paper is presented. In particular, Section~\ref{chap:SubInexProj} is devoted to recall the concept of relative feasible inexact projection and some  new properties about this concept are presented. Section~\ref{chap:SGM}  describes the SGP method with a general nonmonotone line search and some particular instances of it are presented.  Partial asymptotic convergence results  are presented in Section~\ref{Sec:PartialConvRes}. Section~\ref{Sec:FullConvRes}   presents  a full   convergence result  and iteration-complexity bounds. Some numerical experiments are provided in Section \ref{chap:NumExp}. Finally, some concluding remarks are made in Section~\ref{chap:Conclusions}.
