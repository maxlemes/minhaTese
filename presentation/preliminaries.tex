\section{The main problem}


\begin{frame}
  \frametitle[c]{The main problem}

  We want to present an inexact version of the scaled gradient projection method  for  \textcolor{purple}{constrained convex optimization problem} as follows

  \bigskip

  \begin{equation} \label{eq:OptP}
    \min \{ f(x) :~   x\in C\},
  \end{equation}

  \bigskip

  where $C$ is a \textcolor{purple}{closed and convex} subset of $\mathbb{R}^n$ and $f:\mathbb{R}^n \to \mathbb{R}$ is a \textcolor{purple}{continuously differentiable function}.
\end{frame}


\begin{frame}
  \frametitle{Scaled Gradient Projection Method\footfullcite{Bonettini2009}}

  \begin{enumerate}
    \item[Step 0.] Choose  $\sigma, \tau \in (0, 1)$, $0 < \alpha_{\min} \leq \alpha_{\max}$. Let $x^0\in C$ and set $k=0$;

    \item[Step 1.] Choose $\alpha_k\in [\alpha_{\min}, \alpha_{\max}]$ and a positive definite matrix $D_k$ and take  $w^{k}\in C$  as
      \begin{equation*}
        w^k := {\cal P}_{C}^{D_k} (x^{k}-\alpha_k D_k^{-1}\nabla f(x^{k}))
      \end{equation*}

      If $w^k= x^k$, then {\bf stop}; otherwise,
    \item [Step 2.] Choose $\tau_k$ and define the next iterate $x^{k+1}$ as
          \begin{equation} \label{eq:IterArm}
            x^{k+1} = x^{k} + \tau_k (w^k - x^{k}).
          \end{equation}
          and go back to the Step 1.
  \end{enumerate}
\end{frame}


\begin{frame}
  \frametitle{Scaled Gradient Projection Method}
  Let  $D$ be a $n\times n$ \textcolor{purple}{positive definite matrix} and $\| \cdot \|_{D} : \mathbb{R}^{n}\rightarrow \mathbb{R}$ be  the norm  defined by
  \begin{equation*}
    \|d\|_{D}:=\sqrt{\left\langle D d,d\right\rangle},\quad \forall d\in \mathbb{R}^{n}.
  \end{equation*}
  For a fixed  constant $\mu \geq 1$,  {\it denote by  ${\cal D}_{\mu}$  the set of \textcolor{purple}{symmetric} positive definite matrices $n\times n$ with all \textcolor{purple}{eigenvalues} contained in the interval $[\frac{1}{\mu}, \mu]$}.
  \begin{itemize}
    \item ${\cal D}_{\mu}$   is compact;
    \item If $D\in {\cal D}_{\mu}$, it follows that $D^{-1}$ also belongs to $ {\cal D}_{\mu}$;
    \item $\forall D\in {\cal D}_{\mu}$,  we obtain
          \begin{equation*}
            \frac{1}{\mu}\|d\|^2\leq \|d\|^2_{D}\leq \mu \|d\|^2, \qquad \forall d\in \mathbb{R}^n.
          \end{equation*}
  \end{itemize}
\end{frame}


% \begin{frame}
%   \frametitle{Preliminaries}

%   \begin{definition}
%     Let $(y^k)_{k\in\mathbb{N}}$ be a sequence in $\mathbb{R}^n$ and   $(D_k)_{k\in\mathbb{N}}$ be  a sequence in ${\cal D}_{\mu}$.  The sequence $(y^k)_{k\in\mathbb{N}}$ is said to be \textcolor{purple}{quasi-Fej\'er convergent} to a set $W\subset \mathbb{R}^n$ with respect to  $(D_k)_{k\in\mathbb{N}}$ if, for  all $w\in W$, there exists a sequence $(\epsilon_k)_{k\in\mathbb{N}}\subset\mathbb{R}$ such that $\epsilon_k\geq 0$, $\displaystyle\sum_{k\in \mathbb{N}}\epsilon_k<\infty$, and
%     \[
%       \|y^{k+1}-w\|_{D_{k+1}}^2\leq \|y^k-w\|_{D_k}^2+\epsilon_k,
%     \]
%     for all $k\in \mathbb{N}$.
%   \end{definition}
% \end{frame}


% \begin{frame}
%   \frametitle{Preliminaries}

%   \begin{theorem}
%     Let $(y^k)_{k\in\mathbb{N}}$ be a sequence in $\mathbb{R}^n$ and   $(D_k)_{k\in\mathbb{N}}$ be  a sequence in ${\cal D}_{\mu}$.   If $(y^k)_{k\in\mathbb{N}}$ is quasi-Fej\'er convergent to a nomempty set $W\subset  \mathbb{R}^n$ with respect to $(D_k)_{k\in\mathbb{N}}$, then $(y^k)_{k\in\mathbb{N}}$ is \textcolor{purple}{bounded}. Furthermore, if a \textcolor{purple}{cluster point ${\bar y}$} of $(y^k)_{k\in\mathbb{N}}$ belongs to $W$, then $\displaystyle\lim_{k\rightarrow\infty}y^k={\bar y}$.
%   \end{theorem}
% \end{frame}

